# 2022/10/25 - Client Meeting W8

Created: October 25, 2022

Created by: Ali Ladha, Lydia Lin

Tags: Client Meeting

- Show the selected photos that the user picked as a small preview?
- The AL assigns an equivalent amount of weight to the selected images, so that the AL algorithm will try to match from this subset of images.
- De-select images from the algorithm input subset, in the chance that users might make a mistake (Feature)
- If making a query to the DB takes too much time, then this becomes an issue immediately
    - An important issue, we should test how fast can we retrieve images from the DB
- What type of queries are generated from the AL algorithm, because that will affect how long the retrieval will take
- The user will see the learning process from the query strategy (one possibility)
- Basically, the hyper-plane or the threshold needs to be re-trained so that the non-matches and matches are the most accurate
- The number of users working on a video isn’t hard-set, so it doesn’t need to be one person or a group, it can be either.
- User Group:
    - Data Evaluator, this user will go through the videos and manually find timestamps and label at each timestamp
    - Data Scientist, they will train and might give the instance of the algorithm to the data evaluator to the
- VGG-16, we use up to one of the last layers to the vectorize the image.
- 5 seconds for image retrieval and AL running
- A potential issue with our Schedule, is that our testing will be last, so if and when we run into any issues, we won’t have ample time to address these timing issues.
- Concern is how efficient is MongoDB in querying vectors

---

UI:
- Display reference photo (or the Class name/Label) -> Class name is preferred
- Up to the algorithm: 
    - Queries from the db (most uncertain, closes,...)
- Have functionality to remove incorrect label from the previous iteration
    - Return only fishes? or return both?
- Algorithm will still learn if you label all non-objects
    - Showing more for this iteration, as input hasn't changed

VGG-16:
- Output 4096 vector. This vector is for the input of the AL algo.
    - Not the 1000 layer.
- Do research on Google “4096 vgg16”
- Can MongoDB store image vectors?
- O-ne layer of vgg16: 
    - The output should be from the 2nd or 3rd last layers
- Then feed it to the algorithm

Prediction vs Display:
- The algorithm will query from the db?
- Query on the vector
- Algorithm query, vector is not feed to the algo
- Strategies to choose modAL: pick one, but don't use random.
- 1 strategy: point closes to the hyperplane

Feedback for the report
- Algorithm base (not the data)
- Fast overview all the data
- Data evaluator: 
    - Look from start to end; 
    - Find for specific images; with this program , distribute of the video

- Testing: waiting <1min; want it in seconds

- Milestones: 
    - We should develop vertically instead of horizontally